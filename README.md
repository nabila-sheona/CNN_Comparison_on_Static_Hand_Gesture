This repository is the container repository of a report that shows a comparative analysis of several pretrained models, fine-tuned on the Sign Language Gesture Images Dataset. The objective of this study is to evaluate the performance of popular pretrained models, including ResNet, VGG16, and InceptionV3, on a sign language gesture recognition task. By leveraging the power of ImageNet-trained weights, we fine-tune these models to classify sign language gestures, a critical application for enhancing communication accessibility. Performance is measured using metrics such as accuracy, precision, recall, and F1 score, and further analyzed using visualizations like t-SNE, confusion matrices, Grad-CAM heatmaps, and Lime visualizations to gain insights into model behavior. The findings aim to contribute to the comparative analysis and model selection guide for specific types of Hand Gesture Recognition Problem.
